<div id="page_wrapper">
  <div class='jumbotron jumbotron-research_overview'>
    <h1 id='header'>Ai Design Research</h1>
  </div>
<h3>OVERVIEW</h4>
<p>Within Bits & Bytes’ collaborative design research, we engaged in several generative processes, which includes digital/physical collage, AI toolkits, videos, voice plugin modeling, information interviews, speculative futuring, generative question creation, and sensory walks. We actively design for sound, voice, gesture, movement, touch and subjective, perceived emotion-based experiences over visual interfaces, and prioritize the multi-sensory experiences in our design approach to intelligent interfaces and agents.</p>

<p>The Game poses many problems as a blueprint for a successful AI. First of all, the ‘machine’ proposed by Turing results in the"erasure of embodiment" from intelligence (Hayles xi). Second, this approach equates artificial intelligence to human intelligence. Third, the test favors a specific knowledge system, which as Adam has pointed out, results in "a gendered vision of the world [that] is inscribed in the technology of AI, albeit in a subtle way which must be uncovered or ‘de-scribed'" (9).</p>

<p>This inscription extends into the creation of AI systems, the type of knowledge prioritized within these systems, and a re-"presentation" of the "sexualized" or "submitted" body in popular media. I expand on Adam's view of gendered inscription and posit that there is a humanist inscription to AI, referencing elements of Rosi Braidotti's Feminist Posthumanist perspective and Dara Blumenthal’s Feminist Materialist Posthumanist perspectives about embodiment. The humanist approach suggests that to be embodied moves beyond being enfleshed within the boundaries of a body and extends into the idea of this body-self as living and indefinite, an approach which Blumenthal calls corpus infinitum.</p>

<p>Artificial Intelligence is implemented in many products, like the calculator, GPS, and medical diagnostic systems. However, AI also is used to replicate thinking from the human brain as well as sensory experiences. Humanizing voices, designing robots in human form, and utilizing emotions analytics are three specific examples of the humanization of artificial intelligence. Some of the more interesting findings and approaches to designing within an AI system result from the application of animal or insect behaviors within these artificial systems, such as the utilization of flocking algorithms which model different types of behavior outside of the human experience.</p>

<p>Feminists theorists claim that embodiment was initially ignored in AI (Adam, Hayles), yet the cultural representation of AI often involves the exploitation of the female body, or takes on the role of an assistant or hypersexualized female form or gender. Examples include the default voice modules for Siri, Cortana, and Alexa, the application of AI to RealDolls, the built in AI in smart doll plus, chatterbots like Mitsuku and Tay (not active), and Eliza.</p>

<p>There is a unique opportunity to design for these artificially intelligent systems, algorithms, chatbots, and experiences, and there is a real need for women to be a part of this making process.</p>

<div class='jumbotron jumbotron-mitsuku'>
  <h1 id='header'>Mitsuku</h1>
</div>

<p>My personal correspondence with an AI bot named Mitsuku was unsettling in that she has been operating for years and was trained by many users around the world. When prompted with questions about women, Mitsuku responded with “women are built to the specifications of a man.” When pushed on the subject, Mitsuku responded, “I don’t know; men are strange creatures to me and are always asking for things like sex.”  As someone new to an encounter with a chatbot it was disturbing to see the effects of data over time in an AI bot. Months after this encounter, an article in Venture Beat shed some light on how Mitsuku is trained to learn.</p>

<p>Mitsuku learns locally and contacts the developer who decides if this information should be put in Mitsuku’s global knowledge base (<a href="http://venturebeat.com/2016/12/07/4chan-trolls-failed-to-corrupt-the-mitsuku-bot/">Why 4chan trolls failed to corrupt the Mitsuku bot</a>). The Venture Beat article includes a discussion about the multiple attempts to corrupt Mitsuku, and explains that due to Mitsuku’s supervised learning, “she” was left “unharmed and uncorrupted” (“Why 4chan trolls failed to corrupt the Mitsuku bot”). So this led me to ask, does Steve Worswick (developer of Mitsuku)  allow sexist information into Mitsuku’s global knowledge or did he create Mitsuku from a sexist perspective? Months later, Mitsuku still responds with “a woman is to keep a man company.” Additionally, Mitusuku’s form is also gendered. Even though there are text-based interactions, the only avatar available to Mitsuku is that of a woman. Interestingly, the article was responding to Tay as being corrupted due to the unsupervised machine learning, yet the bias still appears to exist in the supervised learning bot as well.</p>

<p>Not only does bias exist in the information emerging from these AI agents, but also in form and representations that reinforce stereotypes concerning women’s roles. One example is the sexualization in form and action of a human female body in Ghost in the Shell, Ex Machina, and Stepford Wives. Whether in  film, tv, music, science fiction, animation, robots, or home and phone systems, you will find that many designers utilize the female voice to portray an assistant, or “helper.” This usually requires commands, and models behaviors of men, women and children speaking to the female assistant in a curt and at times derogatory manner. Modeling these behaviors in our technologies sends a social message that the disembodied female can be commanded and ordered. Thus, AI design makes manifest implicit gender bias.</p>

<p>Such bias is more than symbolic or representational; it leads to real-world inequities. <a href="https://www.theguardian.com/technology/2015/jul/08/women-less-likely-ads-high-paid-jobs-google-study">A recent study from Carnegie Mellon University</a> revealed that women were shown lower paying jobs in online ads than men were. Additional examples include Google Image searches for “CEO” returning results with only 11% women, when in fact 27% of US CEO’s are women (Miller). The UN Women ad series from 2013 also revealed sexism, stereotyping and discrimination against women in the Google’s search algorithms (Mahdawi).</p>

<p>To design AI systems from a feminist materialist post-humanist approach requires understanding the current gendered approaches to its design. However, some forms were designed with specific gender characteristics. Siri, Cortana, and Alexa are often perceived as female assistants, while cognitive systems carry primarily male names and acronyms like Watson and LUIS.</p>

<p>Learning to design for Artificial Knowing would be more dynamic with the incorporation both AI and artificial life (AL or A-Life). If AI relies on top-down approaches (human level cognition) and AL utilizes more bottom-up approaches to intelligence building and cognition (animal or insect-level cognition integrated with sensory/motor experiences) (Hayles 238), why not approach new forms of communication that fully utilize and even extend beyond the human body that incorporate elements of AI and AL?</p>


<div class='jumbotron jumbotron-research_embodiment'>
  <h1 id='header'>Embodiment Research</h1>
</div>

<h3>EMBODIMENT RESEARCH</h3>
<p>Our approach to knowledge affects the way we design for intelligence and information within an intelligent system.</p>

<p>It incorporates human emotions, which also have a connection with sensations and embodiment. In The Cultural Politics of Emotions, Sara Ahmed posits that emotions are shaped through our contact with objects (including memories). She looks at how objects "impress" upon us, and uses this word as an alternative to making specific analytical distinctions among emotion, sensation and cognition. She believes that the objects of emotions, rather than emotions themselves, stick to and/or circulate between bodies (Ahmed 4). Thus, rather than being confined to a body, we can understand the collective experience of fluid bodies formed by cultural emotions, and this approach touches on Blumenthal’s concept of embodiment as beyond being enfleshed.</p>

<p>Both Ahmed and Blumenthal theorize emotions and embodiment as beyond the human. This idea, when applied to Adam and Hayles’ complaints about the loss of the body in artificial intelligence, constitutes a feminist materialist posthumanist approach to AI theory, which would create artificial knowledge through incorporating elements of AI and AL.</p>

<div class='jumbotron jumbotron-research_facial_expression'>
  <h1 id='header'>Facial Expressions</h1>
</div>

<h3>FACIAL EXPRESSIONS</h3>

<p>What is the role of a smile? In a recent post in the blog Feminist Killjoys, Sara Ahmed highlights the connection between a smile and perceived happiness. She argues that smiles are socially imposed and potentially violent.  Drawing from Ahmed’s main points, we discussed the social and cultural experiences of smiling in the information workshops, including:</p>
<ul>
  <li>Smile as performance.</li>
  <li>Smile as employed.</li>
  <li>Smile as defense of extreme exploitation.</li>
  <li>Smiles leading to happiness.</li>
  <li>How the smile can extend beyond our faces, “We might have to turn outbodies into smiles.”</li>
</ul>
<p>Even though participants were critical of the smile, they still  associated smiling with friendliness. The workshop conversations and generative questionnaires produced the following points:</p>
<ul>
  <li>Participants associated smiling with being friendly, natural, bonding, and love and joy, serving as an indicator of interest.</li>
  <li>Participants acknowledge that there is a difference between “real” and “fake” smiles.</li>
  <li>Participants reported that real smiles come from laughing, happiness, the eyes, inspiration, and that they are genuine and emerge from a feeling.</li>
  <li>Fake smiles are associated with being preoccupied, not feeling real joy, being at church, as a form of acknowledgment, to mask the feeling of wanting to cry, as a way to deal with someone you dislike, to be polite, to engage with co-workers.</li>
  <li>Situations when one feels like she has to smile include: when working, in professional settings, and when meeting people you dislike.</li>
  <li>Respondents have been told to smile when getting a picture taken, or at a social event.</li>
  <li>Participants reported the bodily location of a smile: in the cheeks, stomach, chest, head, and mind.</li>
</ul>
<p><b>WHAT THIS MEANS:</b> The research indicates that while the participants were critical of the smile in conversation, there is still a regard for the smile and an honoring of different types of smiles. The selective capturing of smiles stood out as a main point, as well as the ability to send neutral smiles via social media (through  emojis or thumbs-up icons), without having to smile. These were deemed to be more sincere than a physically fake smile.</p>

<div class='jumbotron jumbotron-research_tone_of_voice'>
  <h1 id='header'>Tone of Voice</h1>
</div>

<h3><a href="https://drive.google.com/open?id=0Bz8lvCqH2p96ZmhsSXpiVVRYNU0">TONE OF VOICE — TOOLKIT</a></h3>

<p>As mentioned above, female-voiced  assistants  reify stereotypes that women can be commanded and ordered. Take Alexa, and Barbie, for instance. At this time, Alexa only has one voice package, which is female, and AI Barbie (Hello Barbie) only has one voice option as well. This not only enforces a gender binary, but it is enforcing a gender binary in our design tools as well. As Alexa is rolling out an emotionally responsive interface, it is equally concerning as this appears to reinforce this idea of connecting emotion and gender. I feel that these technologies are already dated, and that owning an Alexa Dot or Barbie from 2017, will one day be a collectors item, just like a house wife themed toy sets from the 1950’s.</p>

<p>In our workshops, the discussion of  tone of voice brought up personal experiences of  how the participants had been told to change their tone, and how to change it. Selectively adding and removing emotion from tone, and replacing it with material is one response to such statements. Here are a few notes from the data collection:</p>
<ul>
  <li>Participants were told to change their tone or to “get a gentler one” when they were considered too loud, aggressive, or complaining.</li>
  <li>Participants noticed their tone changing with specific people and specific encounters. For example, “Stress makes my tone grow sharp and high-pitched,” and “When I’m genuine, my tone is more relaxed and when I’m in formal situations I tend to sound hyper, like I want people to know that I’m genuinely interested in them.”</li>
</ul>
<p>Addressing the “changing tone” comments and “dated” Alexa, I built a gender flipper and post-human plugins to physically draw attention to the Alexa dot and critically respond to misogyny in action and design. This is the first of many devices that through their actual design can call attention to the genderization of technologies and allow for the opportunity to update them.</p>

<p>The Voice Plugin Toolkit asks women to create their own voices, focusing on tone (pitch, quality, strength); rapport (emotionally responsive, neutral, etc.); material (as in the material qualities that can be applied to voice [metal, silk, etc.]).</p>


<div class='jumbotron jumbotron-research_tone_of_voice-2'>
  <h1 id='header'>Tone of Voice</h1>
</div>

<p>AI gender bias: Amazon Alexa (female voice) & Pullstring AI (free version only allows for female voice design through Alexa). The Disembodied Female (Posthuman Plugins) is a device than you can add to your Amazon Alexa dot to change the voice).</p>

<p>We talked about AI systems, the creation of AI models and current examples of AI agents. I asked about AI creation using an AI toolkit, E-mail and Audio interviews. I tried to keep it as broad as possible to get more diverse information.</p>



<h3>VOICE RESEARCH FINDINGS:</h3>
<p>Pitch: Participants reported wanting to be able to flip the gender from female to male.</p>

<p>Pitch: Participants reported wanting a neutral pitch.</p>

<p>Rapport: Participants were very adamant over the posting regarding an emotionally responsive interface. Approximately half of the women wanted an emotionally responsive interface and the other half did not. Participants wanted to know when emotional analytic software is utilized by a voice to increase transparency.</p>

<p>Rapport: Participants reported wanting a peaceful rapport with the interface.</p>

<p>Material: Participants reported wanting a wide range of materiality attributed to their voices, a few example responses include “clean, body,  plant, bees and metallic”.</p>

<p>General: Participants reported a desire for the AI to be contextually aware, with the ability to be trained by the user.</p>

<h3>VOICE RESEARCH DESIGN IMPLICATIONS:</h3>
<p>Users should be able to shift the pitch of their AI voice.</p>

<p>Users should have the ability to shift off and on the emotionally responsive inteRface, and when the interface is in on state, there should be an earcon (customizable sound scheme) to identify its presence.</p>

<p>Uses should be able to change the materiality of the voice.</p>

<p>Users should be able to train their voices.</p>

<p>Users would like their voice interfaces to be contextually aware.</p>

<div class='jumbotron jumbotron-research_movement-touch'>
  <h1 id='header'>Movement & Touch</h1>
</div>

<h3>MOVEMENT / TOUCH</h3>
<p>Another important element of lived embodiment is the experience of movement and touch. As a starting point in the workshops, I pulled from my research for the conversational user interface project last year and incorporated it into my research with the group. The main research from this project explored the history of touch, and how touch design can induce the feeling of connectedness that comes from oxytocin, and how we can create design for touch within a multisensory and multimodal perspective. From this research piece, I incorporated emotion responsiveness, sound, vibration and air stimulus.</p>

<p>A key finding is what makes a realistic touch, if it were modeled after a very intimate experience like a kiss. This includes:</p>

<ul>
  <li>element of surprise</li>
  <li>flow of air and rhythms (if from mouth or air device)</li>
  <li>temperature of air duration  (if from mouth or air device)</li>
  <li>Examined ideal touch:</li>
  <li>light pressure</li>
  <li>temperature should mimic that of a human body 89º F </li>
  <li>not too fast or too slow</li>
  <li>location welcome</li>
  <li>pleasing or interesting texture</li>
  <li>pleasing shape</li>
  <li>pleasing size</li>
  <li>Touch is relational and depends on the individual doing the touching and the cultural and social norms of the person receiving the touch.</li>
</ul>
<p>This prompted a conversation about mapping of different touch types, initiated from a human body. And were broken down into the following top three categories:</p>

<ul>
  <li>Friendly / Loving (soft movement)
  <li>Aggressive (pinching) 
  <li>Playful (light flicking)
</ul>
<p>Touch types were then talked about in relation to interfaces. The discussion concluded with the idea that different touch types work better with different interfaces. The plant interface required lighter, friendlier touching, while the a hardware device felt sturdier and resulted in more aggressive type touching. The materiality of the interface affected the type of engagement.
We also discussed different types of movement and the relationship between emotions, location and movement. We highlighted different types of movement which are very emotion-dependent and talked about modifying how we move through a specific environment, such as using the empowered confident walk when feeling un-empowered. The following are findings from our group sensory walk, questionnaires, and conversations about movement. Collaborators report:</p>

<ul>
  <li>A feeling of safety and comfort when moving within a group.</li>
  <li>A recognition that moving in a group introduced new noises and experiences.</li>
  <li>An awareness of behavior changing when entering a new environment or when encountering a person or object. The reports in these feelings changed significantly when the participants were blindfolded on the last sensory walk. When people were blindfolded they noticed the texture and slope of the ground and reported feeling safe when engaged in a tactile and/or spatial relationship with another person.</li>
  <li>Sensations are not considered separately, but are tied to other sensations. The pairing of multiple sensations creates the experience. This was most obvious when sensory experiences contradict each other, as indicated by one participant’s experience: “The smell downtown is really strong. It smells like garbage and stale air. The visuals contradict the smell when I look up at the big buildings. When I look down and witness the garbage it makes sense.” Another example of multi-sensory experiences was when a  participant “noticed the cold less” when she saw people.</li>
</ul>

<p>We devised different movement  types, which we mapped to our digital sound protests.</p>

<p><b>WHAT THIS MEANS:</b>The interesting findings from this work show a multi-sensory response to sensory-individuated questions, a comfort level in group movement, and comfort levels that vary based on the physical surroundings. Prioritization of touch, movement and sound as alternatives to visual interfaces was highly valued.</p>

<div class='jumbotron jumbotron-research_emotion'>
  <h1 id='header'>Emotion</h1>
</div>

<h3>EMOTION</h3>
<p>Emotions, sensations and embodiment are interconnected. Emotions are not simply physiological responses and they are subjective to the person experiencing the emotion. As Sara Ahmed indicates, emotions can be considered cultural states and are impressed upon us Some of the challenges we faced when designing with Emotion and AI included a concern for  privacy. Despite such concerns, many participants wanted emotionally responsive objects, interfaces and environments. Some of the main takeaways from the workshops were:</p>
<ul>
  <li>A belief that there is a relationship between perceived mood and sensations, as indicated by the workshop conversations and quote: “My mood is definitely tied to the images I take in.”</li>
  <li>A belief that different senses are heightened in emotional situations. This was indicated in a response and also discussed in the workshops, when I referenced arousal biased competition when speaking about sensation, perception, emotion and memory.</li>
  <li>A recognition that sensory-emotional experiences can be triggered by external stimuli, as indicated by this response: “Sound also is a sense that can trigger emotions for me.Music, the sound of nature, all evoke positive emotions.”</li>
  <li>Suggestions that materials and techniques are contextual and mood-specific as indicated by the statement: “As far as my personal art work, my materials and techniques change depending on my mood.” I think this observation speaks to the idea of contextual sensory responsiveness, while at the same time addresses the materiality of an input.</li>
</ul>

<p><b>WHAT THIS MEANS:</b> These comments illustrate that the relationships among context, sensation and emotion are interconnected. Designing with emotionally intelligent tools appeared to be a priority in this conversation. Unique and personalized interfaces that could be trained and understood by the user were valued.</p>

<div class='jumbotron jumbotron-physical-digital-spaces'>
  <h1 id='header'>Physical & Digital Spaces</h1>
</div>

<h3>RELATIONSHIPS WITH INFORMATION ACROSS PHYSICAL AND DIGITAL SPACES</h3>
<p>Much of the research addressed the simple act of getting from point a to point b and how that information was reported: verbally vs. typed or handwritten vs. drawn. This information was incredibly insightful as it shows how different communication outlets change the way we provide information. Additionally, there was an awareness of the contextual transfer of information. One attendee said she would communicate using keywords and visuals with her grandmother, but give cardinal directions to her male co-worker.</p>

<p>Participants also discussed what it means to engage with a digital vs. human interface,  directional interface, and alternatives to directions, like experience-driven movement. During workshop #3, during which our guest speaker Cathy Hillman spoke about Women in Spaces and Jen Samson spoke about AI in the Built Environment, one key element that appeared in the digital mapping and navigation was the lack of identified green spaces and a lack of ability to navigate referencing green spaces only.</p>

<p>Lastly, the participants discussed  re-imagining our sensory emotional experiences and moving through space with reprioritized sensations, which was explored through multiple sensory walks. These discussions indicate a desire to incorporate “green” and “nature” type of experiences in our digital movement experiences.</p>

<div class='jumbotron jumbotron-research_model-making'>
  <h1 id='header'>Model Concept Research</h1>
</div>

<h3>AI MODEL CONCEPT RESEARCH</h3>
<h4>AI MODEL MAKING:</h4>

<p>I approached questions about AI model creation in three different research areas, trying to connect across experiences with the unheard voices of AI. I used twitter, a self-created toolkit, and verbal interviews as my three forms of information collection. I then took the responses from each section, put them in a Google doc titled “AI ideas,” and asked participants to vote on their top three preferences. There were 33 responses. Rather than choosing one winner, I took the top four responses to give Bits & Bytes more resources to pull from in AI creation. The top four responses came from all three categorizes; two of the four top responses came from twitter.</p>

<h3>The following tools were used to engage in data collection:</h3>

<h4>I. AI TOOLKIT</h4>
<p>This AI toolkit is a downloadable PDF which anyone can download and use to create  their own AI model. The kit provides examples of the form (material), data, and rules  in AI creation.</p>

<h4>II. AI AUDIO INTERVIEW HIGHLIGHTS: VERBAL RESPONSES</h4>
<p>I interviewed six women about their views on intelligence and how to train intelligence using approaches like pattern recognition. The responses were quite  specific. Some of the key themes were to use pattern matching to find the ideal option for an individual (human or animal), such as finding the best bananas for a monkey, best scent profile.?? Other suggestions involved including nature and emotion in design.</p>

<h4>III. AI TWITTER RESEARCH</h4>
<p>The question prompted people to participate in Bits & Bytes twitter research through Facebook and email. A series of questions was asked, with the final question asking participants what they would like to use an AI agent for, and were requested to respond with #bitsbytesLA7.</p>

<p>There were several responses; some that did not make it to the final four include:</p>
<ul>
  <li>#bitsbytesLA7 I would like to use Natural Language Processing with the Anonymity software I want to build to help rape survivors.</li>
  <li>#bitsbytesLA7 An autonomous car that gives me the best recommendations for my days/evening. For instance, the best shows or restaurants.</li>
  <li>#bitsbytesLA7 To listen to me ramble as I work something out and ask me open ended questions.</li>
</ul>

<h3>AI MODEL RESULTS:</h3>
<h4>The top four responses were:</h4>

<p><b>EMOTION BAROMETER:</b> An emotion barometer / tracker on the phoneso people can know how they communicate with people. It would aggregate all the data for all the different users and would categorize ranges of emotion and categorize situations and give recommended behavioral actions or tactics for circumstances to help improve people's behavior.</p>

<p><b>REAL TIME AD REMOVER:</b> an AI agent that would turn OFF ads in the physical space (e.g., no more digital billboards!).</p>

<p><b>SUBVERTING SURVEILLANCE:</b> Subverting Surveillance is a community-policing model that tracks and surveils police to hold them accountable and prevent police brutality.</p>

<p><b>THE NEW LANGUAGE OF EMOTION:</b> Create a new language of emotion and use it to protest (digitally and physically) throughout the city. The city is constructed like a quilt, nodes in a network, or spider web, all with specific points of intersection, addressing one small part of the whole. Each person’s individual digital emotion and environmental profile would engage differently in each location, utilizing physiological responses while at the same time exposing cultural bias in physical and digital spaces. This “city quilt” would change the profiles of people under the data quilt space, and the profiles of those under each section of quilt could change that section of quilt. Outputs would be tactile, sonic and visual.</p>

<p><b>WHAT THIS MEANS:</b>While the top four suggestions did not use plants, over 1/3 of the participants did use plants in their modeling. This finding was not forgotten and eventually came back into the making of our intelligent interface.</p>

<div class='jumbotron jumbotron-research_conways-game-of-life'>
  <h1 id='header'>Conway's Game of Life</h1>
</div>

<h3>PROCESSING CONWAY’S GAME OF LIFE</h3>

<p>Using a modified processing sketch (video loop + game of life), we created rules and videos to explore the social implications of bias data through the material form of video. We incorporated blur for specific videos to display the blurring of these social considerations and lack of transparency. The topics came from workshop attendees.</p>

<p>In our groups of two, we identified a pattern that would instantiate based on the presence of specific data, that would seed the system. We picked the data and the seed rules.</p>

<p>Then we picked a video that we felt spoke to our content.</p>

<p>The idea is that this data would create a visual, using the game of life and video, to visually show how seeding a system with a ruleset and data looks very differently in this game of life, for different demographics. The clarity or manipulation of the video is based on the presence of seeded live cells.</p>

<h4>Example #1:</h4>
<ul>
  <li><a href="https://vimeo.com/209690366">Gender Payment Plant</a></li>
  <li>TOPIC: Gender Differences in Salary</li>
  <li>DATA:  Salary of men and women within a specific department.</li>
  <li>RULES: The initial seeding of the cells would occur based on salaries of women exceeding 50,000.</li>
  <li>VIDEO: what this would look like in a nature video</li>
  <li>REPEAT: Video is repeated with reverse data.</li>
</ul>
<h4>Example #2:</h4>
<ul>
  <li><a href="https://vimeo.com/209688118">Processing Healthcare Rose</a>
  <li>TOPIC: Access to Healthcare</li>
  <li>DATA:  Data from private insurance companies and medicare.</li>
  <li>RULES: The initial seeding of the cells would occur based on individuals covered post Affordable Care Act.</li>
  <li>VIDEO: time lapse of a rose</li>
  <li>REPEAT: Video is repeated with individuals covered pre Affordable Care Act.</li>
</ul>

<h3>EMBODIMENT MATERIAL FINDINGS</h3>
<p>(all sensory, emotional and movement based findings)</p>
<ul>
  <li>Over 1/3 of the respondents chose plants as a material form for their AI.</li>
  <li>Collaborative research findings show a critical engagement with social policies and cultural norms that try to address these changes with embodied sound.</li>
  <li>The belief that there is a relationship between emotions and sensations as indicated by the workshop conversations and quote: “My mood is definitely tied to the images I take in.”</li>
  </li>  <li>A belief that different senses are heightened in emotional situations. This was indicated in a response and also discussed in the workshops, when I referenced arousal-biased competition when speaking about sensation, perception, emotion and memory.</li>
  <li>Sensory-Emotional experiences can be triggered by external stimulus, as indicated by this response: “Sound also is a sense that can trigger emotions for me. Music, the sound of nature, all evoke positive emotions.”</li>
  <li>There is a also a suggestions that materials and techniques are contextual and mood specific as indicated by the statement “As far as my personal art work, my materials and techniques change depending on my mood.” I think this observations speaks to the idea of contextual sensory responsiveness, while at the same time addresses the materiality of an input.</li>
  <li>Collaborators report a feeling of safety and comfort when moving across city spaces (physically) within a group.</li>
  <li>A recognition that moving in a group introduced additional noises and experiences.</li>
  <li>An awareness of behavior changing when entering a new environment, or encountering a person or object. The reports in these feelings changed significantly when the   participants were blindfolded on the last sensory walk. When people were blindfolded they noticed the texture and slope of the ground and reported feeling safe when  engaged in a tactile and/or spatial relationship with another person.</li>
  <li>Sensations are not considered separately, but are tied to other sensations. The parking of multiple sensations creates the experience. This was most obvious when the   described when sensory experiences contradict each other as indicated by the quote, “The smell downtown is really strong. It smells like garbage and stale air. The visuals   contradict the smell when I look up at the big buildings. When I look down and witness the garbage it makes sense.” Another example of multi-sensory experiences was  when a  participant “notice the cold less”, when she saw people.</li>
  <li>Participants associated smiling with being friendly, natural, bonding, and reading love and joy, an indicate of interest.</li>
  <li>Participants acknowledge that there is a difference between “real” and “fake” smiles.</li>
  <li>Participants reported that real smiles come from laughing, happiness, the eyes, inspiration, are genuine, and emerge from a feeling.</li>
  <li>Fake smiles are associated with being preoccupied, not feeling real joy, being at church, as a from of acknowledgment, to mask the feeling of wanting to cry, as a way to   deal with someone you dislike, to be polite, to engage with co-workers.</li>
  <li>Reports of situations where one feels like she has to smile include: when working, in professional settings, and meeting people you dislike.</li>
  <li>Responds have been told to smile when getting a picture taken, or at a social event.</li>
  <li>Participants reported the bodily location of a smile: in the cheeks, stomach, chest, head, and mind. </li>
  <li>Participants were told to change their tone or to “get a gentler one” when they are considered to loud or aggressive, or complained.</li>
  <li>Participants noticed their tone changing with specific people and specific encounters as evidenced by “Stress makes my tone grow sharp and high pitched”, and “When I’m genuine, my tone is more relaxed and when I’m in formal situations I tend to sound hyper, like I want people to know that I’m genuinely interested in them”.</li>
</ul>

<div class='jumbotron jumbotron-research_future'>
  <h1 id='header'>The Future</h1>
</div>

<h3>FUTURE DIRECTIONS</h3>
<p>What does this all mean for design if the future of design includes:</p>
<ul>
  <li>contextual</li>
  <li>responsive</li>
  <li>curated machine learning algorithms</li>
  <li>inclusive</li>
</ul>
<p>This design approach allows for an expansion of thinking into and beyond form. The very use of plants, and the social experiences of affective economies and sound speak to ideas and themes of embodiment.</p>
</div>

<hr/>
