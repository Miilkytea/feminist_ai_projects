<div class="ai-design-tools">
  <h2>AI Design Tools</h2>

  <h3>AI Design Research Findings</h3>

  <div>
    <%= image_tag 'feminist-artificial-intelligence_design-research_findings.jpg', alt:'' %>
  </div>

  <h3>Insights</h3>
  <div>
    <%= image_tag 'feminist-artificial-intelligence_design-research_insights.jpg', alt:'' %>
  </div>

  <h4>Based on my research with the community through conversations, design investigations and questionnaires I found</h4>
  <ul>
    <li>Participants reported that it is more interesting to have the ability to disable or modify learning behaviors in AI systems.</li>
    <li>Participants reported wanting the ability to directly expose social bias through material AI projects.</li>
    <li>Participants were interested in different approaches to AI, and felt that a mixing of approaches) 
      such as symbolic and connectionist) might yield new thoughts about how to design AI systems.</li>
    <li>Participants were interested in designing with their own “little data” for curated intelligent experiences.</li>
    <li>When possible, participants wanted artificial intelligence to be to be housed in a physical form, which could serve as the interface.</li>
    <li>Participants wanted to “feel connected with (or be a part of) their environment” or “react to their environment” with their bodies.</li>
    <li>Users would like access to basic information about the AI system (such as supervised or unsupervised learning) and what data is being used.</li>
    <li>Users would like to be aware of both positive and negative bias that exists in AI systems.</li>
  </ul>

  <h3>Future Directions</h3>
  <div>
    <%= image_tag 'feminist-artificial-intelligence_design-research_future.jpg', alt:'' %>
  </div>

  <h4>Implications for designing future AI systems</h4>
  <ul>
    <li>When utilizing Emotion, Sentiment, and Mood analysis in AI systems, designers should be trained by the individual or group of users, over time and should be changeable.</li>
    <li>Users should be able to disable or modify learning behaviors in AI systems.</li>
    <li>Users would like to design their own “little data” for curated intelligent experiences.</li>
    <li>Users should be able to assign mix and match physical materials with learning algorithms.</li>
    <li>Designers should be able to combine and mix and match AI models (ie connectionist & symbolic) and curate algorithms to design for unique AI experiences.</li>
    <li>When applicable, designers should use the form of the object as the interface, to reflect the intent or function of the AI system.</li>
    <li>Designers should be designing for embodiment in AI.</li>
    <li>Designers and developers should include as much information as possible about the algorithms used in physical and digital products.</li>
  </ul>

  <h2>AI Design Tools</h2>

  <div>
    <%= image_tag 'feminist-artificial-intelligence_design-research_process.jpg', alt:'' %>
  </div>

  <p>As the design research findings indicate, users would like more transparency
  regarding the decisions and information going into an AI system, and a
  recognition of bias within an existing system. This is a challenge for
  designers, as we need to start to design to recognize cultural and social
  assumptions and bias in the creation of our AI design tools.</p>

  <p>Many users reported a complete disconnection from algorithmic creation and AI
  design.  The cultural AI design tool is an in browser generator that helps
  people designing AI systems to remove assumptions of favoring a specific type of
  AI approach. It additionally draws attention to the need to include cultural and
  social considerations in the design, while at the same time offering a
  prescriptive playful approach to expose people to different types of thinking in
  AI design. Below is a rough sketch of this cultural design tool.</p>

  <div>
    <%= image_tag 'feminist-artificial-intelligence_culture-design-tool.jpg', alt:'' %>
  </div>

  <h3>Overall Design Implications</h3>
  <h4>When utilizing Emotion, Sentiment, and Mood analysis in AI systems, designers should be trained by the individual or group of users, over time and should be changeable.</h4>
  <ul>
    <li>Users should be able to disable or modify learning behaviors in AI systems.</li>
    <li>Users would like to use AI in for social critique and as a tool for collaboration with other humans.</li>
    <li>Users would like to design their own “little data” for curated intelligent experiences.</li>
    <li>Users should have control over the data that is put into the AI system.</li>
    <li>Users should be able to assign mix and match physical materials with learning algorithms.</li>
    <li>When applicable, should be able to use the form of the object as the interface.</li>
    <li>Designers should try to create AI systems that consider embodiment (not sure how to word this).</li>
    <li>Designers and developers should create AI systems that allow for physical or digital outcome (for things like political action).</li>
    <li>As designers we can use AI to identify, explore and expose both known and unknown bias, and can work with the community to create projects that reflect inequalities within groups and organizations.</li>
    <li>As designers we consider how to use to design for creative and embodied experiences.</li>
  </ul>
</div>
